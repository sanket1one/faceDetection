import numpy as np  # pip install numpy
import cv2

def generate_dataset():
    face_classifier = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
    def face_cropped(img):

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = face_classifier.detectMultiScale(gray ,1.3 ,5)

        if faces is ():
            return None
        for(x ,y ,w ,h) in faces:
            cropped_face = img[y: y +h ,x: x +w]
        return cropped_face

    cap = cv2.VideoCapture(0)
    img_id = 0

    while True:
        ret, frame = cap.read()
        if face_cropped(frame) is not None:
            img_id +=1
            face = cv2.resize(face_cropped(frame), (200, 200))
            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
            file_name_path = "data/" + "sanket." + str(img_id) + ".jpg"
            cv2.imwrite(file_name_path, face)
            cv2.putText(face, str(img_id), (50 ,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0 ,255 ,0), 2)

            cv2.imshow("Cropped_face", face)
            if cv2.waitKey(1) == 13 or int(img_id) == 1000:       # pressing enter will end the program
                break

    cap.release()
    cv2.destroyAllWindows()
    print("Collecting samples is completed !!!")

generate_dataset()

# def my_label(image_name):
#     name = image_name.split('.')[-3] #sanket.1jpg -> sanket  1 jpg
#     # if we have two person in our dataset
#     if name=="sanket":
#         return np.array([1,0])
#     elif name=="manisha":
#         return np.array([0,1])
#
#     # if we have three person in our dataset
#     # if name == "sanket":
#     #     return np.array([1,0,0])
#     # elif name== "manisha":
#     #     return np.array([0,1,0])
#     # elif name=="aniket":
#     #     return np.array([0,0,1])


# # create data
# import os
# from random  import shuffle
# from tqdm import tqdm # its a processing box
#
# def my_data():
#     data = []
#     for img in tqdm(os.listdir("./data")):
#         path = os.path.join("data", img)
#         img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
#         img_data = cv2.resize(img_data, (50,50))
#         data.append([np.array(img_data), my_label(img)])
#     shuffle(data)
#     return data
#
# data = my_data()
#
#
# train = data[:1600] # [x-train,y_trian]
# test = data[1600:]  # y=mx+c
#
# x_train = np.array([i[0] for i in train]).reshape(-1,50,50,1)
# print(x_train.shape)
# y_train = [i[1] for i in train]
# x_test = np.array([i[0] for i in test]).reshape(-1, 50, 50 ,50 , 1)
# print(x_test.shape)
# y_test = [i[1] for i in test]
#
#
# # Creating the model
#
# import tensorflow as tf
# import tflearn
# from tflearn.layers.conv import conv_2d, max_poop_2d
# from tflearn.layers.core import input_data, dropout, fully_connected
# from tflearn.layres.estimaor import regression
#
#
# tf.reset_default_graph()
# convnet = input_data(shape=[50,50,1])
# convnet = conv_2d(convnet, 32, 5 , activation='relu')   # 32 is filters an strides=5 so that filter will move 5 pixelor unit at a time
# # relu replace the negative value with 0 don't do anyhing with positive values
#
# convnet = max_pool_2d(convnet, 5)
# convnet = conv_2d(convnet, 64, 5 ,activation='relu')
#
# convnet = max_pool_2d(convnet, 5)
# convnet = conv_2d(convnet, 128, 5 ,activation='relu')
#
# convnet = max_pool_2d(convnet, 5)
# convnet = conv_2d(convnet, 64, 5 ,activation='relu')
#
# convnet = max_pool_2d(convnet, 5)
# convnet = conv_2d(convnet, 32, 5 ,activation='relu')
#
# convnet = fully_connected(convnet, 1024, activation='relu')
# convnet = dropout(convnet, 0.8) # prevent the cnn from overfitting
# convnet = fully_connected(convnet, 2, activation='softmax') # convnet, no.of person connected
# convnet  = regression(convnet, optimizer='adam', learning_rate=0.001, loss='categorical_cossentropy')
# model = tflearn.DNN(convnet, tensorboard_verbose = 1)
# #0 :loss & metric(Best SPeed)
# #1: Loss, Metric & Gradients.
# #2. Loss, Metric, Gradient & Weight
# #3. Loss, Metric, Gradient,Wieght, Activation & Sparsity
# model.fit(x_train, y_train, n_epoch =12, validation_set=(x_test,y_test), show_metric = True, run_id="FRS")
#
#
#
#
# ## Let's Visualize the data and make prediction
#
#
#
# def generate_dataset():
#     face_classifier = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
#     def face_cropped(img):
#         gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#         faces = face_classifier.detectMultiScale(gray ,1.3 ,5)
#
#         if faces is ():
#             return None
#         for(x ,y ,w ,h) in faces:
#             cropped_face = img[y: y +h ,x: x +w]
#         return cropped_face
#
#     cap = cv2.VideoCapture(0)
#     img_id = 0
#
#     while True:
#         ret, frame = cap.read()
#         if face_cropped(frame) is not None:
#             img_id +=1
#             face = cv2.resize(face_cropped(frame), (200, 200))
#             face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)
#             # file_name_path = "data/" + "sanket." + str(img_id) + ".jpg"
#             file_name_path = "images_for_visualisation/" + str(img_id)+ '.jpg'
#             cv2.imwrite(file_name_path, face)
#             cv2.putText(face, str(img_id), (50 ,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0 ,255 ,0), 2)
#
#             cv2.imshow("Cropped_face", face)
#             if cv2.waitKey(1) == 13 or int(img_id) == 20:       # pressing enter will end the program
#                 break
#
#     cap.release()
#     cv2.destroyAllWindows()
#     print("Collecting samples is completed !!!")
#
# generate_dataset()
#
#
#
#
# def data_for_visulation():
#     Vdata = []
#     for img in tqdm(os.listdir("Images for visulation")):
#         path = os.path.join("images_for_visualisation", img)
#         img_num = img.split('.')    #1 jpg
#         img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
#         img_data = cv2.resize(img_data, (50,50))
#         Vdata.append([np.array(img_data), img_num])
#     shuffle(Vdata)
#     return Vdata
#
#
# Vdata = data_for_visulation()
#
# import matplotlib.pyplot as plt #  pip install matplotlib
# fig = plt.figure(figsize=(20,20))
# for num, data in enumerate(Vdata[:20]):
#     img_data = data[0]
#     y = fig.add_subplot(5,5,num +1)
#     image = img_data
#     data = img_data.reshpae(50,50, 1)
#     model_out = model.predict([data])[0]
#
#     if np.argmax(model_out) == 0:
#         my_label = "sanket"
#     elif np.argmax(model_out) == 1:
#         my_label = 'manisha'
#     else:
#         my_label = 'aniket'
#
#     y.imshow(image, cmap='gray')
#     plt.title(my_label)
#
#     y.axes.get_xaxis().set_visible(False)
#     y.axes.get_yaxis().set_visible(False)
#
# plt.show()